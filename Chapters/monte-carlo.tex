\chapter{Monte-Carlo Techniques}

In this chapter we discuss some techniques useful in \ac{mc} simulations
of systems in statistical-physics.
In such systems these techniques wil be used to calculate thermal averages using random numbers. Let
$Z$ denote the partition function and $\mathcal{H}$ the Hamiltonian of the system. Then the thermal
average of an observable $\mathcal{O}$ is defined as
\begin{equation}
    \label{eq:Monte:thermalAverage}
    \langle\mathcal{O}\rangle = \frac{1}{Z}\sum_\psi\mathcal{O}(\psi)e^{-\beta\mathcal{H}(\psi)},
\end{equation}
where $\psi$ denotes states of the system and we thus sum over all possible states. In the case of
a quantum system, then this sum turns into a multi-dimensional integral over quantum coherent states.
Now any attempt at estimating these integrals through an interpolation scheme is destined to fail because if we divide
a $1$-dimensional integral into $M$ pieces and the error of the interpolation scheme scales as $\sim M^{-\kappa}$,
then applied to a $d$-dimensional integral, its error will scale as $M^{-\kappa/d}$.
What \ac{mc} techniques then provides is a way of using random numbers in calculating
Eq.~\eqref{eq:Monte:thermalAverage} without actually summing over all the states. We do this by drawing random states
$\psi_i$ from a carefully selected probability distribution and using statistics to estimate how close the resulting
thermal average is likely to be to the true thermal average. Letting $M$ be the number of samples, then the
error scales as $M^{-1/2}$ and is independent of the number of dimensions of the integral.

As in the case of the stationary phase approximation, the calculation of the sum in Eq.~\eqref{eq:Monte:thermalAverage} can be made much more effective
by considering which terms give large contributions. If we have a probability distribution $\pi(\psi)$ of sampled states $\psi$ that has peaked at states
that gives large contributions to $\langle\mathcal{O}\rangle$, then our estimate will converge much quicker to the true value than if we were to
sample states uniformely. In a sense we are interested in sampling only the important states, and hence this is called importance sampling. Let
$\{\tilde{\psi}_i\}$ be a set of states that are uniformly sampled, while $\{\psi_i\}$ are sampled with probability distribution $\pi(\psi_i)$. The
statistical estimator $\bar{\langle\mathcal{O}\rangle}$ of the thermal average of the observable $\mathcal{O}$ is then
\begin{equation}
    \label{eq:Monte:importanceSampledThermAvg}
    \bar{\langle\mathcal{O}\rangle} = \sum_{i}\mathcal{O}(\tilde{\psi}_i)\frac{e^{-\beta\mathcal{H}(\tilde{\psi}_i)}}{Z(\{\tilde{\psi}_i\})} = \sum_{i}\mathcal{O}(\psi_i)\frac{e^{-\beta\mathcal{H}(\psi_i)}}{\pi(\psi_i)Z(\{\psi_i\})}.
\end{equation}
Now assuming that the state-dependence of the observaible is less important than the exponential, then the largest contributions to the sum will
come from states that are such that $e^{-\beta\mathcal{H}}/Z$ is large. We thus want to pick states such that 
\begin{equation}
    \label{eq:Monte:boltzmannDist}
    \pi(\psi_i) = e^{-\beta\mathcal{H}(\psi_i)}/Z.
\end{equation}
Then, given $M$ states sampled according to this probability distribution, the statistical estimator reduces to the arithmetic average
\begin{equation}
    \label{eq:Monte:arithmTherm:Avg}
    \bar{\langle\mathcal{O}\rangle} = \frac{1}{M}\sum_i\mathcal{O}(\psi_i).
\end{equation}

\section{Markov-Chain Monte-Carlo method}

\ac{mcmc} is a strategy of obtaining a sample of random states $\psi_k$ where the the states are drawn sequentially in such
a way that the probability $P_k(\psi)$ of drawing a new state $\psi_k=\psi$ is only dependent on what the last
state $\psi_{k-1}$ was. The chain developed by drawing states in this way thus has no memory of the rest of the content
of the chain, except for its last link $\psi_{k-1}$. A chain with this property is called a Markov-Chain, hence the name.

We want the sampled states to be drawn according to the probability distribution $\pi(\psi_k)$ discussed above. This is assured
with the criteria of ergodicity and detailed balance. Ergodicity means in this context that the states are drawn in such a way
that if we were to draw infinitely many states, then we would have drawn all possible states $\psi$ in the original sum in
Eq.~\eqref{eq:Monte:thermalAverage}.

The criterion of detailed balance comes from the idea that we want the probability that
a certain state is drawn to be independent of when the state is drawn in the chain. Let $P_k(\psi)$ be the probability
that $\psi$ is drawn at the $k$th point in the chain. Because of the Markov-chain property, this probability is fully determined
by the probability that the previous state in the chain transitions into the state $\psi$. Let $\mathcal{T}(\psi'\to\psi)$ denote
the probability that state $\psi'$ transitions into state $\psi$, \ie that the state $\psi$ is drawn given a previously drawn
state $\psi'$. Then the probability that the state drawn at the point $k+1$ in the chain is $\psi$, is given by
\begin{equation}
    \label{eq:Monte:pointProbability}
    \begin{split}
        P_{k+1}(\psi) &= \sum_{\psi'}P(\psi_k = \psi'\;\land\;\psi'\text{ transitions to }\psi)\\
        &= \sum_{\psi'}P_k(\psi')\mathcal{T}(\psi'\to\psi)\\
        &= P_k(\psi) + \sum_{\psi'}\Big[P_k(\psi')\mathcal{T}(\psi'\to\psi) - P_k(\psi)\mathcal{T}(\psi\to\psi')\Big],
    \end{split}
\end{equation}
where we have used that $\sum_{\psi'}\mathcal{T}(\psi\to\psi') = 1$ since the state must transition to some state. Now since
the probability should be invariant of the point in the chain and be given by our desired probability density,
we demand $P_{k+1}(\psi) = P_k(\psi) = \pi(\psi)$ such that the sum vanishes.
Because the probability density $\mathcal{T}$ is arbitrary, the sum needs to vanish term-wise, yielding the final condition
of detailed balance:
\begin{equation}
    \label{eq:Monte:detailedBalance}
    \pi(\psi')\mathcal{T}(\psi'\to\psi) = \pi(\psi)\mathcal{T}(\psi\to\psi').
\end{equation}
This states that for the process to be invariant of the point in the chain, it has be reversible.

\section{Metropolis-Hastings method}

The \ac{mh} method is an algorithm for drawing states in a Markov-Chain that spesifies a transition probability
$\mathcal{T}(\psi\to\psi')$ between states $\psi$ and $\psi'$ that satisfies the detailed balance criterion. The algorithm proceeds
as follows:
\begin{enumerate}
    \item Given a state $\psi_k$, pick a new state $\psi_p$ where the process of picking this state has an, as of now, arbitrary
        probability distribution denoted $q(\psi_p\,|\,\psi_k)$ with the only requirement being that it leads to ergodic selection.
    \item Accept this new proposed state $\psi_p$, with the probability $\alpha(\psi_p\,|\,\psi_k)$,
        defined as
        \begin{equation}
            \label{eq:Monte:MH:acceptanceProb}
            \alpha(\psi_p\,|\,\psi_k) = \min\bigg\{1,\;\frac{\pi(\psi_p)q(\psi_k\,|\,\psi_p)}{\pi(\psi_k)q(\psi_p\,|\,\psi_k)}\bigg\}.
        \end{equation}
    \item If $\psi_p$ is accepted we set $\psi_{k+1}=\psi_p$. If not, then $\psi_{k+1}=\psi_k$. Finally return to 1. to pick the next
        state in the chain.
\end{enumerate}
By this procedure, then the probability of transitioning between a state $\psi$ at point $k$ to a state $\psi'$ at point $k+1$ is
given by probability that the state $\psi'$ is picked and that $\psi'$ is accepted such that
\begin{equation}
    \label{eq:Monte:MH:transitionProb}
    \mathcal{T}(\psi\to\psi') = \alpha(\psi'\,|\,\psi)\,q(\psi'\,|\,\psi).
\end{equation}
This transition probability satisfies detailed balance since inserting Eq.~\eqref{eq:Monte:MH:transitionProb} and
\eqref{eq:Monte:MH:acceptanceProb} yields
\begin{equation}
    \label{eq:Monte:MH:detailedBalance}
    \begin{split}
        \pi(\psi')\mathcal{T}(\psi'\to\psi) &= \min\{\pi(\psi)q(\psi'\,|\,\psi),\;\pi(\psi')q(\psi\,|\,\psi')\}\\
        &= \pi(\psi)\mathcal{T}(\psi\to\psi').
    \end{split}
\end{equation}

\subsection{Practical considerations}

Usually, the above is a bit too general for practical implementation since we would have to calculate, or know, the probability
distribution $q(\psi'\,|\,\psi)$ used in picking new proposed states. If we assume $q$ to be symmetric such that
\begin{equation}
    \label{eq:Monte:MH:pickDistributionSymmetry}
    q(\psi'\,|\,\psi) = q(\psi\,|\,\psi'),
\end{equation}
then we don't need to calculate it explicitely since it cancels out of the equation for $\alpha$ in Eq.~\eqref{eq:Monte:MH:transitionProb}.

A further simplification can be acheived by inserting the expression for $\pi(\psi)$ in Eq.~\eqref{eq:Monte:boltzmannDist} into the $q$
symmetric version of $\alpha$, which in this case reduces to
\begin{equation}
    \label{eq:Monte:MH:reducedTransitionProb}
    \alpha(\psi'\,|\,\psi) = \min\Big\{1,\;e^{-\beta\big[\mathcal{H}(\psi') - \mathcal{H}(\psi)\big]}\Big\}.
\end{equation}
The significance of this form is that we see the transition probability is only dependent on the difference between the energy of the
updated state and the original state. If the state of the system $\psi$ is a collection of site-dependent sub-states $\phi(\v{r}_j)$,
\eg how the state of an Ising chain is given by a collection of site-dependent spins, then the calculation of $\mathcal{H}(\psi)$
has to take into account all the sites. If we update only a single site $\v{r}_j$ of $\psi$ to get $\psi'$, which we call a local
\ac{mc} update, then all the sites that do not have an interaction with $\v{r}_j$ cancels out in the
difference $\mathcal{H}(\psi')-\mathcal{H}(\psi)$. Then we only need to calculate the the difference in the sub-states that are
affected by $\v{r}_j$ to calculate the energy-difference. This is an essential property to have when creating a parallelized version
of this algorithm since different parts of the lattice of sites then can be updated in an asynchronuous manner without affecting
each other. In other words: by simplifying to the energy difference, the update scheme becomes local which makes local \ac{mc}
updates grid-parallelizable.

To use pseudo-random numbers to accept a new state $\psi'$ with probability $\alpha$ we pick a uniformely distributed number $r\in(0,1]$. Then
we use the fact that
\begin{equation}
    \label{eq:Monte:MH:rProbability}
    P[r \leq \alpha(\psi'\,|\,\psi)] = \alpha(\psi'\,|\,\psi),
\end{equation}
so that updating the state if $r\leq\alpha$ is equivalent to updating the state with probability $\alpha$. Given the form of $\alpha$ in
Eq.~\eqref{eq:Monte:MH:reducedTransitionProb} then
\begin{equation}
    \label{eq:Monte:MH:rEquivalences}
    r \leq \alpha(\psi'\,|\,\psi)\;\Leftrightarrow\;\ln r \leq -\beta[\mathcal{H}(\psi')-\mathcal{H}(\psi)].
\end{equation}
To update the state with probability $\alpha$ we thus simply take the natural logarithm of $r$ and update the state if the right hand
side of Eq.~\eqref{eq:Monte:MH:rEquivalences} is true.

To obtain good statistics, we want, as a rule of thumb, the acceptance rate to be about $30-60\%$ for high temperature states%
\footnote{High temperature states refers to states that are well above any transition temperature of the system.}. %
The acceptance rate is defined as the
number of proposed states $\psi'$ that are accepted, divided by the total number of proposed states, and will in general be proportional
to the transition probability $\alpha(\psi'\,|\,\alpha)$. This can be adjusted by changing the way
new states $\psi'$ are proposed. Let $\psi$ be composed of site specific substates $\phi(\v{r}_j)$ and let a state $\psi'$ be proposed
by changing the values of the sub-state $\phi(\v{r}_0)$. Choosing values closer to the original sub-state $\phi(\v{r}_o)$, the difference
$\mathcal{H}(\psi')-\mathcal{H}(\psi)$ decreases such that $\alpha(\psi'\,|\,\psi)$ in
Eq.~\eqref{eq:Monte:MH:reducedTransitionProb} approaches $1$ and the acceptance rate increases.

Proposing states such that the acceptance rate is very high, in this case means that the states do not change very much with each \ac{mc} update. This
can lead to freezing of the simulation, where the measurements do not change even after a significant number of \ac{mc} updates because
a large number of \ac{mc} updates in a certain direction is needed to significantly change the measurements. On the other hand, too low
of a acceptance rate will also freeze the simulation since then obviously states are very unlikely to change, leading to the same
measurements repeatedly. Ultimately, whether the acceptance rate should be considered too high or too low, should be guided by the physics of
the system since in the case that the system has reached a gobal minimum in the energy-lanscape and has low temperature,
the proper statistics is obtained by
an update scheme that gives a low acceptance rate. It is not advisable to change the acceptance rate during a measurement run over
decreasing temperatures as this has tended to freeze the measurements at varying temperatures leading to confusion when trying to
find a transition point.

\section{Thermalization procedures}

Thermalization in a \ac{mcmc} simulation refers to the process of discarding a number of \ac{mc} updates before starting to measure the
states in the Markov-chain. The reason for doing this is because the first states in the chain will usually be very unlikely states in the
ensamble of states, and thus give these states an artificially high statistical weight, unless we measure long enough.
That time could be very long indeed if the starting states are very unlikely, thus to get
measurements in a reasonable time, these unlikely starting states are discarded.

How many states to discard is usually estimated with the help of an energy vs. \ac{mcs}%
\footnote{A Monte-Carlo sweep is a term used for attempting to update all the different sites of a system once.} %
plot as shown in Figure~\ref{fig:Monte:therm_plot}. Since the initial state usually has a different energy than the average energy in the Markov-chain,
the energy can be seen to rapidly stabilize to the average value in such a plot. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{thermalization_plot_1compXY.pdf}
    \caption{Thermalization of a $64^3$ single-component $XY$-system from random initial states to a numerical temperature $T=0.5$.
    The different curves represent the energy of different realizations of the same
    system initialized at different random states over several \ac{mcs}s. The random initial states have a relatively high energy that stabilizes
    to the same value for all realizations in an exponential fashion.}
    \label{fig:Monte:therm_plot}
\end{figure}

Whether the energy stabilizes from above or below will depend
on what the initial state is and what the temperature of the simulation is set to. For an ab-iniito state, in which the values of the sub-states
are set to uniformly distributed random values in their validity range, this normally corresponds to a very high temperature and
high energy state, hence thermalizing from such a state will have the energy stabilize from above. Another possibility for an ab-inito
state is some kind of mean-field minimal solution of the Hamiltonian where sub-states at different sites are correlated. In this case the
energy will usually be low and the thermalization energy will stabilize from below. This option has the disadvantage that if the mean field
solution lies inside some local energy minimum then simulations based on it might not be able to get out and find the global miniomum,
as opposed to states that are thermalized from high energy where some might find this local minimum while others fall down in the global one.
In general it is best to thermalize several independent systems from different initial conditions that yield quantitatively similar results
to make it less likely that the results come from a local minimum.

A last suggestion for an initial state of the system,
is the last state of a previous simulation. In this case the thermalization will stabilize depending on the relative temperature
of the two simulations. To be sure that the measurements are not correlated with the measurements of the last simulation one should discard
This is a useful practice if gathering results over an extended temperature range where the systems need a large
thermalization time in order to stabilize. One would then typically start measuring at a high temperature and then decrease the temperature
sucessively in steps with a thermalization period and measure period for each step.

For systems prone to fall into local minima it was found that a more careful thermalization period analogous to the measurement procedure 
described above, decreased the probability of freezing into such minima. Instead of thermalizing from a high energy - high temperature state
directly down to the desired temperature, which we call quenching, a cooldown period was added. During the cooldown period, the temperature was
lowered stepwise from a high temperature $T_0$ to a target temperature $T$ with intermediate temperatures
\begin{equation}
    \label{eq:Monte:Therm:geometricTemperatures}
    T_k = \Big(\frac{T}{T_0}\Big)^{\frac{k}{N}}T_0.
\end{equation}
The intermediate temperatures were geometrically distributed to ensure highest density of intermediate steps at lower temperatures. At
each temperature step, a fixed number of \ac{mcs}s were preformed such that more \ac{mcs}s were done towards the lower temperature than
higher. This was done because the simulations in general took longer to thermalize when the temperature decreased. An example of how the
energy changed during such a thermalization period is shown in Figure~\ref{fig:Monte:cooldown_plot}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{cooldown_full_model.pdf}
    \caption{Energy pr. site of a $64^3$ site model system of a $p+ip$ chiral superconductor during the cooldown stage. The temperature is
    lowered as a geometric sequence and a fixed number of \ac{mcs}s are done at each temperature step. Comparing with the thermalization
    in Figure~\ref{fig:Monte:therm_plot} we see that the cooldown period gives a significantly more gradual thermalization.}
    \label{fig:Monte:cooldown_plot}
\end{figure}

The cooldown period was then followed by a conventional thermalization stage where the temperature was held constant at $T$. In
most cases the energy had already stabilized at this point such that the energy measurements during this extra thermalization
stage typically only showed fluctuations around the mean.


\section{Parallel tempering}

Parallel tempering is a method of simulating multiple systems over a range of different temperatures where the systems can exchange
positions with their neighbors in this temperature range according to a \ac{mh}-like update step. Since all the different systems all have the same parameters
except for temperature, when viewed from the perspective of a single temperature, this leads to a normal Metropolis-Hastings \ac{mcmc}
simulation with an occational global update of all sites of the system whenever the current system exchanges with the system at a neighboring
temperature. From the dual perspective of a single system, \ac{pt} allows the system to move in temperature space.

This global updating, or movement in temperature space, has the advantage that it can prevent systems from getting stuck in local minima
by allowing them to move to a higher temperature where it is easier to fluctuate to a more favorable configuration. In systems that
has a jagged energy-landscape with lots of local minima this can be of great benefit and can reduce the required time it takes
to measure observables with a certain accuracy by several orders of magnitude \cite{Katzgraber09}.

To implement parallel tempering \ac{mcmc} in a temperature centric perspective,
let $\{T_i\}_{i=1}^M$ be a sorted list of $M$ ascending temperatures, and let $\{\lambda_i\}_{i=1}^M$
be a list of indices $\lambda$, that refer to replica states $\{\psi_\lambda\}_{\lambda=1}^M$ of the system such that the replica with temperature $T_i$
is given by $\psi_{\lambda_i}$ and its energy is given by $E_{\lambda_i}$.
The simulation then proceeds according to the algorithm
\begin{enumerate}
    \item Preform $\Delta t$ normal Monte-Carlo updates on all replica states, \eg using the \ac{mh} method.
    \item For each replica state $\psi_\lambda$ calculate the corresponding energy $E_\lambda$.
    \item For each pair of neighboring temperatures $T_i$ and $T_{i+1}$ where $T_i<T_{i+1}$:
        \begin{enumerate}
            \item calculate the quantity
            \begin{equation}
                \label{eq:Monte:PT:delta}
                \Delta = (E_{\lambda_{i+1}} - E_{\lambda_i})\Big(\frac{1}{T_{i+1}} - \frac{1}{T_i}\Big).
            \end{equation}
            \item Then swap the indices $\lambda_i \leftrightarrow \lambda_{i+1}$ with probability $\min\{1, e^\Delta\}$. This can
                as in the \ac{mh} method be done by generating a random number $r\in[0,1)$ and then swapping indices if
                $\ln r \leq \Delta$.
        \end{enumerate}
    \item If the replicas $\psi_\lambda$ have internal knowledge of their temperatures, then distribute $T_i$ to $\psi_{\lambda_i}$, for all
        temperatures $T_i$.
    \item Sample observables and return to 1.
\end{enumerate}

This algorithm is very efficiently parallelizable since the bulk of computing time will be going to doing the $\Delta t$ \ac{mc} updates which can
be performed in parallel by having each replica state $\psi_\lambda$ be assigned to a separate thread / processor. If each thread in addition
keeps track of the replicas energy at the end of the \ac{mc} updates, the only information that needs to be transferred between worker processes and
the process doing the \ac{pt} update step is the values of the energies to the \ac{pt} process, and afterwards: the set of new temperatures
back to the worker processes. The \ac{pt} process itself only has to 
calculate $M-1$ values and move around the indices in an array.

For the parallel tempering method to generate good statistics efficiently, some care should be taken in the distribution of the temperatures $T_i$.
A rule of thumb is to distribute them geometrically, \ie according to
\begin{equation}
    \label{eq:Monte:PT:geometricTemperatures}
    T_i = \bigg(\frac{T_M}{T_1}\bigg)^{\frac{k-1}{M-1}}T_1,
\end{equation}
with the argument that lower temperatures generally have a lower relaxation rate. With geometric distribution, the temperatures are denser towards
the low end such that the accpetance rate of swaps of replicas at neighboring temperatures would in general become more flat and independent of temperature.
Should the specific heat diverge at some point in the temperature range as in the case of a phase transition, then this distribution would no
longer be optimal since the acceptance probability of temperature swaps is inversely proportional to $C_v$ and thus the accpetance rate would no
longer be flat.

From the perspective of an individual replica, the overall goal with the distribution of temperatures is to maximize the number of the replica moves
from the lowest temperature $T_1$, up to the highest temperature $T_M$ and back to the lowest temperature again. This will then maximize the number
of statistically independent visits of the system at each temperature. The hope then is that a flat accpetance rate with respect to the distributed
temperatures will provide a good number of round-trips. With more advanced methods such as the feedback-optimized parallel-tempering Monte-Carlo
method the number of round-trips can be optimized \cite{Katzgraber06}.

\section{Grid parallelization}

\section{Reweighting}
